{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAKYZFF3HYFe"
   },
   "source": [
    "IMDB Review Sentiment Analysis\n",
    "\n",
    "In this assignment, we will explore one dataset for binary sentiment classification. The original dataset contains 50,000 reviews â€” 25,000 positive and 25,000 negative reviews. \n",
    "\n",
    "The number of stars would be a good proxy for sentiment classification. For example, we could pre-assign the following:\n",
    "1. At least 7 out of 10 stars => positive (label=1)\n",
    "2. At most 4 out of 10 stars => negative (label=0)\n",
    "\n",
    "Here, we sample the original dataset and create a small-size data for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKJEVWf5P6w1"
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #ignore any warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PE5GiW2_HYF1"
   },
   "outputs": [],
   "source": [
    "# examine the first 5 rows of X (including the feature names)\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"train_IMDB.csv\")\n",
    "df_test  = pd.read_csv(\"test_IMDB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "zm76ZfPiP6w4",
    "outputId": "0c667f55-753b-417e-83fe-21c4f29328ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the first review I've wrote for IMDb s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The missing star\", who competed for the Golde...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deep Water (2006) ****&lt;br /&gt;&lt;br /&gt;\"It is indif...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm a rather pedestrian person, with somewhat ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The film is very fast-moving, bizarre and colo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  label\n",
       "0  This is the first review I've wrote for IMDb s...  positive      1\n",
       "1  \"The missing star\", who competed for the Golde...  positive      1\n",
       "2  Deep Water (2006) ****<br /><br />\"It is indif...  positive      1\n",
       "3  I'm a rather pedestrian person, with somewhat ...  positive      1\n",
       "4  The film is very fast-moving, bizarre and colo...  negative      0"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "EpUVSNF-l8ki",
    "outputId": "aa2aeedb-c6a2-421f-9898-5b4c24eebea6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie was made by a bunch of white guys t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despite a silly premise,ridiculous plot device...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do they insist on making re-makes of great...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The One and the Only!&lt;br /&gt;&lt;br /&gt;The only real...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While I hold its predecessor, \"Fast Times At R...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  label\n",
       "0  This movie was made by a bunch of white guys t...  negative      0\n",
       "1  Despite a silly premise,ridiculous plot device...  positive      1\n",
       "2  Why do they insist on making re-makes of great...  negative      0\n",
       "3  The One and the Only!<br /><br />The only real...  positive      1\n",
       "4  While I hold its predecessor, \"Fast Times At R...  positive      1"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-ZmmFd2P6w4"
   },
   "outputs": [],
   "source": [
    "X_train = df_train.review\n",
    "y_train = df_train.label\n",
    "X_test = df_test.review\n",
    "y_test = df_test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvi92UHTP6w8"
   },
   "source": [
    "## Task 1: Check the data shape (2 points)\n",
    "\n",
    "How many training data and testing data do we have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPDqH_s4P6w9",
    "outputId": "81d71472-9e8e-4fae-c30f-1ce1e49846a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(15000, 3)\n"
     ]
    }
   ],
   "source": [
    "# write your answer\n",
    "print(df_train.shape) #25000 rows and 3 columns\n",
    "print(df_test.shape) #15000 rows and 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn29J0dSHYG-"
   },
   "source": [
    "### Vectorizing the IMDB data using Bag-of-Words method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdKk7416HYG_"
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer. We set the vocab size to 200\n",
    "num_features = 200\n",
    "vect = CountVectorizer(max_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOcXm4IhHYHC"
   },
   "outputs": [],
   "source": [
    "# fit on training data and transform to vector (document-term matrix)\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBBqzEZwHYHE",
    "outputId": "ce5364d9-48f7-46e8-b2a4-4d996205d966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 163)\t4\n",
      "  (0, 82)\t3\n",
      "  (0, 153)\t10\n",
      "  (0, 57)\t1\n",
      "  (0, 174)\t2\n",
      "  (0, 58)\t2\n",
      "  (0, 144)\t2\n",
      "  (0, 192)\t2\n",
      "  (0, 100)\t1\n",
      "  (0, 31)\t2\n",
      "  (0, 116)\t2\n",
      "  (0, 11)\t3\n",
      "  (0, 177)\t1\n",
      "  (0, 83)\t2\n",
      "  (0, 67)\t2\n",
      "  (0, 80)\t2\n",
      "  (0, 54)\t2\n",
      "  (0, 16)\t1\n",
      "  (0, 189)\t1\n",
      "  (0, 169)\t3\n",
      "  (0, 61)\t1\n",
      "  (0, 162)\t1\n",
      "  (0, 148)\t1\n",
      "  (0, 157)\t1\n",
      "  (0, 107)\t1\n",
      "  :\t:\n",
      "  (24999, 153)\t6\n",
      "  (24999, 144)\t2\n",
      "  (24999, 192)\t1\n",
      "  (24999, 31)\t1\n",
      "  (24999, 11)\t3\n",
      "  (24999, 177)\t4\n",
      "  (24999, 83)\t4\n",
      "  (24999, 169)\t4\n",
      "  (24999, 113)\t1\n",
      "  (24999, 103)\t3\n",
      "  (24999, 145)\t1\n",
      "  (24999, 70)\t1\n",
      "  (24999, 139)\t1\n",
      "  (24999, 121)\t1\n",
      "  (24999, 33)\t1\n",
      "  (24999, 117)\t1\n",
      "  (24999, 45)\t1\n",
      "  (24999, 63)\t1\n",
      "  (24999, 159)\t1\n",
      "  (24999, 118)\t2\n",
      "  (24999, 126)\t1\n",
      "  (24999, 4)\t1\n",
      "  (24999, 55)\t1\n",
      "  (24999, 166)\t1\n",
      "  (24999, 37)\t1\n"
     ]
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "print(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YyudMiUHYHF",
    "outputId": "0e030138-02f5-463b-8f74-4edd73aa28bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 6)\t3\n",
      "  (0, 11)\t3\n",
      "  (0, 14)\t4\n",
      "  (0, 15)\t1\n",
      "  (0, 16)\t2\n",
      "  (0, 17)\t5\n",
      "  (0, 18)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 30)\t6\n",
      "  (0, 31)\t3\n",
      "  (0, 32)\t2\n",
      "  (0, 33)\t2\n",
      "  (0, 34)\t3\n",
      "  (0, 37)\t2\n",
      "  (0, 42)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 50)\t1\n",
      "  (0, 52)\t1\n",
      "  (0, 54)\t2\n",
      "  (0, 59)\t1\n",
      "  (0, 60)\t1\n",
      "  (0, 61)\t1\n",
      "  (0, 65)\t1\n",
      "  :\t:\n",
      "  (14998, 168)\t1\n",
      "  (14998, 169)\t1\n",
      "  (14998, 170)\t1\n",
      "  (14998, 178)\t1\n",
      "  (14998, 183)\t1\n",
      "  (14998, 184)\t1\n",
      "  (14998, 194)\t1\n",
      "  (14999, 2)\t1\n",
      "  (14999, 11)\t1\n",
      "  (14999, 19)\t1\n",
      "  (14999, 49)\t1\n",
      "  (14999, 68)\t1\n",
      "  (14999, 79)\t1\n",
      "  (14999, 83)\t1\n",
      "  (14999, 110)\t1\n",
      "  (14999, 114)\t1\n",
      "  (14999, 116)\t1\n",
      "  (14999, 137)\t1\n",
      "  (14999, 146)\t1\n",
      "  (14999, 148)\t1\n",
      "  (14999, 153)\t1\n",
      "  (14999, 163)\t2\n",
      "  (14999, 169)\t2\n",
      "  (14999, 177)\t1\n",
      "  (14999, 195)\t1\n"
     ]
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# examine the document-term matrix\n",
    "print(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clXu3pdoHYHo"
   },
   "source": [
    "## Task 2: Use logistic regression (3 points)\n",
    "\n",
    "1. Train the model using X_train_dtm\n",
    "2. Test the model using X_test_dtm\n",
    "3. Report the training time (**CPU Time**)\n",
    "4. Report the testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkU5JwJ8HYHq"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "# instantiate a logistic regression model\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yOqDTjZP6xR"
   },
   "source": [
    "train the model and report the training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQ_0BRPFHYHs",
    "outputId": "52736d36-89ed-40c9-ce02-37520f21efb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time of Logistic regression with 200 features is : 0.829 s\n"
     ]
    }
   ],
   "source": [
    "# write your code\n",
    "import time\n",
    "\n",
    "t0=time.time()\n",
    "logreg.fit(X_train_dtm,y_train)\n",
    "t_logr_200 = round(time.time()-t0, 3)\n",
    "print(\"training time of Logistic regression with 200 features is :\", t_logr_200, \"s\") # the time would be round to 3 decimal in seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4eLg8r3P6xS"
   },
   "source": [
    "test the model and report the testing accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jX_BxUMUP6xT",
    "outputId": "e71418fc-08ca-4266-d509-4be0fc11c506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Logistic regression with 200 features is : 0.7653333333333333\n"
     ]
    }
   ],
   "source": [
    "# write your answer\n",
    "ypred=logreg.predict(X_test_dtm)\n",
    "a_logr_200 = metrics.accuracy_score(y_test, ypred)\n",
    "print('accuracy of Logistic regression with 200 features is :' , a_logr_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXzQG4q5P6xT"
   },
   "source": [
    "## Task 3: Use Linear SVM (3 points)\n",
    "\n",
    "1. Train the model using X_train_dtm\n",
    "2. Test the model using X_test_dtm\n",
    "3. Report the training time (**CPU Time**)\n",
    "4. Report the testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kV5XjZeP6xU"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_linear = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywOICMHHP6xU"
   },
   "source": [
    "train the model and report the training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ip72nhhUP6xV",
    "outputId": "4ca6a27f-5ad0-42ea-917f-527c3b627286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time of Linear SVM with 200 features is : 0.0 s\n"
     ]
    }
   ],
   "source": [
    "# write your code\n",
    "t0=time.time()\n",
    "t_SVM_200 = round(time.time()-t0, 3)\n",
    "svm_linear.fit(X_train_dtm,y_train)\n",
    "print(\"training time of Linear SVM with 200 features is :\",t_SVM_200 , \"s\") # the time would be round to 3 decimal in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQZaxvRjP6xV"
   },
   "source": [
    "test the model and report the testing accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JoHt9wZbP6xW",
    "outputId": "314aac89-efa2-4977-bd81-e4cf82abef0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Linear SVM with 200 features is : 0.7633333333333333\n"
     ]
    }
   ],
   "source": [
    "# write your answer\n",
    "ypred=svm_linear.predict(X_test_dtm)\n",
    "a_SVM_200 = metrics.accuracy_score(y_test, ypred)\n",
    "print('accuracy of Linear SVM with 200 features is :' , a_SVM_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6ZlsuLoP6xW"
   },
   "source": [
    "## Task 4:  Set vocab size to 2000  (3 points)\n",
    "\n",
    "1. Change the number of features to 2000, i.e., a new vocabulary containing 2000 words.\n",
    "2. Convert the text data into vectors via the new vocabulary.\n",
    "3. Re-train Logistic regression (default settings as Task 2).\n",
    "4. Report the training time and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuQoZQztP6xX"
   },
   "outputs": [],
   "source": [
    "# write your code\n",
    "vect = CountVectorizer(max_features=2000)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# instantiate a logistic regression model\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA5g4ovrP6xX"
   },
   "source": [
    "report the training time and testing accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0T30zCOP6xb",
    "outputId": "8bee33ee-781f-4057-f50a-e8315074a90e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time of Logistic regression with 2000 features is : 1.331 s\n",
      "accuracy of Logistic regression with 2000 features is : 0.7633333333333333\n"
     ]
    }
   ],
   "source": [
    "# write your answer\n",
    "\n",
    "t0=time.time()\n",
    "logreg.fit(X_train_dtm,y_train)\n",
    "t_logr_2000 = round(time.time()-t0, 3)\n",
    "print(\"training time of Logistic regression with 2000 features is :\", t_logr_2000, \"s\") # the time would be round to 3 decimal in seconds\n",
    "\n",
    "a_logr_2000=metrics.accuracy_score(y_test, ypred)\n",
    "print('accuracy of Logistic regression with 2000 features is :' , a_logr_2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEjJ2yKzP6xc"
   },
   "source": [
    "## Task 5:  Model Comparison (4 points)\n",
    "\n",
    "In the above three tasks, we have trained three models. \n",
    "1. Compare their performances. Which model was able to acheive highest accuracy? Which model's training time was the longest? Try to explain your findings.\n",
    "2. Based on Task 2 model, Task 3 model adopted a new classifcation/machine learning model (from Logistic Regression to SVM) and Task 4 used different features for text data (from 200 words to 2000 words). Which method was able to improve the model accuracy more? Try to explain why it is that. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5izGcJBP6xd",
    "outputId": "2f766148-e906-4d62-ff89-55b76673f6ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression with 200 features is : 0.7653333333333333 Training time of Logistic Regression with 200 features is : 0.829\n",
      "Accuracy of Logistic Regression with 2000 features is : 0.7633333333333333 Training time of Logistic Regression with 2000 features is : 1.331\n",
      "Accuracy of LinearSVM with 200 features is : 0.7633333333333333 Training time of LinearSVM with 200 features is : 0.0\n"
     ]
    }
   ],
   "source": [
    "# write your answer\n",
    "print('Accuracy of Logistic Regression with 200 features is :',a_logr_200,'Training time of Logistic Regression with 200 features is :',t_logr_200)\n",
    "print('Accuracy of Logistic Regression with 2000 features is :',a_logr_2000,'Training time of Logistic Regression with 2000 features is :',t_logr_2000)\n",
    "print('Accuracy of LinearSVM with 200 features is :',a_SVM_200,'Training time of LinearSVM with 200 features is :',t_SVM_200)\n",
    "\n",
    "\n",
    "\n",
    "#As we can clearly see that Logistic regression model which was trained on 2000 features took most time in training\n",
    "#In case of SVM it is more robust i.e. due to optimal margin gap between separating hyper planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45U_nbrTP6xd"
   },
   "source": [
    "## Task 6 (Bonus)\n",
    "\n",
    "Try to improve the model performance further. \n",
    "\n",
    "If your solution is able to achieve a testing accuracy that is over 88%, you will get 2 extra points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEg7nRBUP6xe",
    "outputId": "21854558-3ec4-4f79-b22a-dec4e3e877df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.1, 'penalty': 'l2'}\n",
      "accuracy : 88.72000000000003\n"
     ]
    }
   ],
   "source": [
    "# write your code\n",
    "\n",
    "# Grid search cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "vect = CountVectorizer(max_features=20000)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train_dtm,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "\n",
    "\n",
    "print(\"accuracy :\",logreg_cv.best_score_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1N1eZ0AuDkp"
   },
   "outputs": [],
   "source": [
    "#Top accuracy was 88.72% achieved by using {'C': 0.1, 'penalty': 'l2'} as paramereters and 20000 feartres in Logistic Regression"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "sn29J0dSHYG-",
    "clXu3pdoHYHo"
   ],
   "name": "Assignment II solved 0.1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
